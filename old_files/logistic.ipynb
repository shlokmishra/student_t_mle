{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4587ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Location-LOGISTIC (scale=1 known)\n",
    "# Same architecture as your Student-location code\n",
    "# =========================\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "from jax import random, vmap, jit\n",
    "from jax.scipy.stats import norm, truncnorm\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.nn import softplus\n",
    "\n",
    "EPS_Z   = 1e-12\n",
    "EPS_U   = 1e-12\n",
    "EPS_DIV = 1e-12\n",
    "\n",
    "# -------------------------\n",
    "# Logistic logpdf (stable)\n",
    "# f(x|loc,s)=exp(-(x-loc)/s)/(s(1+exp(-(x-loc)/s))^2)\n",
    "# log f = -t - log s - 2*softplus(-t), t=(x-loc)/s\n",
    "# -------------------------\n",
    "@jit\n",
    "def logistic_logpdf(y: jnp.ndarray, loc: jnp.ndarray, scale: jnp.ndarray) -> jnp.ndarray:\n",
    "    t = (y - loc) / scale\n",
    "    return -t - jnp.log(scale) - 2.0 * softplus(-t)\n",
    "\n",
    "# -------------------------\n",
    "# Score transform for location-logistic (scale=1):\n",
    "# score in mu is (1/s) * tanh( (x-mu)/(2s) )\n",
    "# For the constrained manifold at mu_star, we use psi(y)=tanh(y/2), y = x - mu_star.\n",
    "# Range: (-1,1), injective.\n",
    "# -------------------------\n",
    "@jit\n",
    "def z_support_logistic():\n",
    "    return (-1.0 + EPS_Z, 1.0 - EPS_Z)\n",
    "\n",
    "@jit\n",
    "def psi_logistic(y: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.tanh(y / 2.0)\n",
    "\n",
    "@jit\n",
    "def sum_psi_logistic(y: jnp.ndarray) -> jnp.ndarray:\n",
    "    return jnp.sum(psi_logistic(y))\n",
    "\n",
    "@jit\n",
    "def psi_inverse_logistic(z: jnp.ndarray):\n",
    "    # unique inverse: y = 2 * atanh(z)\n",
    "    # z_min, z_max = z_support_logistic()\n",
    "    # z = jnp.clip(z, z_min, z_max)\n",
    "    y = 2.0 * jnp.arctanh(z)\n",
    "    return y  # single branch\n",
    "\n",
    "@jit\n",
    "def log_psi_prime_abs_logistic(y: jnp.ndarray) -> jnp.ndarray:\n",
    "    # psi'(y) = (1/2) * sech^2(y/2) = (1/2)*(1 - tanh^2(y/2)) = (1/2)*(1 - psi(y)^2)\n",
    "    z = psi_logistic(y)\n",
    "    return jnp.log(0.5) + jnp.log(jnp.maximum(1.0 - z*z, 1e-30))\n",
    "\n",
    "# -------------------------\n",
    "# f_Y under current mu, expressed in y = x - mu_star\n",
    "# If X ~ Logistic(loc=mu_current, scale=1), then Y = X - mu_star ~ Logistic(loc=mu_current-mu_star, scale=1).\n",
    "# -------------------------\n",
    "@jit\n",
    "def fy_logpdf_logistic(y: jnp.ndarray, mu_current: jnp.ndarray, mu_star: jnp.ndarray) -> jnp.ndarray:\n",
    "    loc = mu_current - mu_star\n",
    "    return logistic_logpdf(y, loc=loc, scale=1.0)\n",
    "\n",
    "# -------------------------\n",
    "# q(z) = f_Y(y(z)) * |dy/dz|\n",
    "# In your Student code you compute q via log f(y) - log|psi'(y)|, i.e. f(y)/|psi'(y)|\n",
    "# because q(z)=f(y(z))*|dy/dz| and dy/dz = 1/psi'(y).\n",
    "# Here injective => single term.\n",
    "# -------------------------\n",
    "@jit\n",
    "def q_logpdf_logistic(z: jnp.ndarray, mu_current: jnp.ndarray, mu_star: jnp.ndarray) -> jnp.ndarray:\n",
    "    z_min, z_max = z_support_logistic()\n",
    "    in_supp = (z > z_min) & (z < z_max)\n",
    "    y = psi_inverse_logistic(z)\n",
    "    log_q = fy_logpdf_logistic(y, mu_current, mu_star) - log_psi_prime_abs_logistic(y)\n",
    "    return jnp.where(in_supp, log_q, -jnp.inf)\n",
    "\n",
    "@jit\n",
    "def q_tilde_logpdf_logistic(z: jnp.ndarray, delta: jnp.ndarray, mu_current: jnp.ndarray, mu_star: jnp.ndarray) -> jnp.ndarray:\n",
    "    return q_logpdf_logistic(z, mu_current, mu_star) + q_logpdf_logistic(delta - z, mu_current, mu_star)\n",
    "\n",
    "# -------------------------\n",
    "# Same z-update as you have, but with logistic q_tilde\n",
    "# -------------------------\n",
    "def update_z_one_logistic(\n",
    "    key: jax.random.PRNGKey,\n",
    "    z_current: jnp.ndarray,\n",
    "    delta: jnp.ndarray,\n",
    "    mu_current: jnp.ndarray,\n",
    "    mu_star: jnp.ndarray,\n",
    "    sigma_z: float\n",
    "):\n",
    "    key_prop, key_u = random.split(key, 2)\n",
    "\n",
    "    low, high = z_support_logistic()\n",
    "\n",
    "    # partner must also lie in (low, high): delta - z in (low, high)\n",
    "    low2  = delta - high\n",
    "    high2 = delta - low\n",
    "\n",
    "    low_int  = jnp.maximum(low,  low2)\n",
    "    high_int = jnp.minimum(high, high2)\n",
    "\n",
    "    valid = low_int < high_int\n",
    "\n",
    "    def do_reject(_):\n",
    "        return z_current, False\n",
    "\n",
    "    def do_update(_):\n",
    "        a = (low_int  - z_current) / sigma_z\n",
    "        b = (high_int - z_current) / sigma_z\n",
    "\n",
    "        z_prop = z_current + sigma_z * random.truncated_normal(\n",
    "            key_prop, shape=(), lower=a, upper=b\n",
    "        )\n",
    "\n",
    "        log_k_cur_to_prop = truncnorm.logpdf(z_prop, a=a, b=b, loc=z_current, scale=sigma_z)\n",
    "\n",
    "        a_back = (low_int  - z_prop) / sigma_z\n",
    "        b_back = (high_int - z_prop) / sigma_z\n",
    "        log_k_prop_to_cur = truncnorm.logpdf(z_current, a=a_back, b=b_back, loc=z_prop, scale=sigma_z)\n",
    "\n",
    "        log_post_cur  = q_tilde_logpdf_logistic(z_current, delta, mu_current, mu_star)\n",
    "        log_post_prop = q_tilde_logpdf_logistic(z_prop,     delta, mu_current, mu_star)\n",
    "\n",
    "        log_alpha = log_post_prop - log_post_cur + log_k_prop_to_cur - log_k_cur_to_prop\n",
    "        log_alpha = jnp.where(jnp.isfinite(log_alpha), log_alpha, -jnp.inf)\n",
    "\n",
    "        u = random.uniform(key_u, minval=EPS_U, maxval=1.0)\n",
    "        accept = jnp.log(u) < log_alpha\n",
    "\n",
    "        z_new = jnp.where(accept, z_prop, z_current)\n",
    "        return z_new, accept\n",
    "\n",
    "    return jax.lax.cond(valid, do_update, do_reject, operand=None)\n",
    "\n",
    "# -------------------------\n",
    "# Pair update: now inverse is unique, no branch sampling needed.\n",
    "# -------------------------\n",
    "def update_xi_xj_one_logistic(key, xi, xj, mu_current, mu_star, sigma_z):\n",
    "    key_z = key\n",
    "\n",
    "    yi, yj = xi - mu_star, xj - mu_star\n",
    "    zi, zj = psi_logistic(yi), psi_logistic(yj)\n",
    "    delta  = zi + zj\n",
    "\n",
    "    zi_tilde, z_accepted = update_z_one_logistic(\n",
    "        key_z, zi, delta, mu_current, mu_star, sigma_z\n",
    "    )\n",
    "    zj_tilde = delta - zi_tilde\n",
    "\n",
    "    z_min, z_max = z_support_logistic()\n",
    "    in_supp_partner = (zj_tilde > z_min) & (zj_tilde < z_max)\n",
    "\n",
    "    def reject_pair(_):\n",
    "        return xi, xj, False, z_accepted\n",
    "\n",
    "    def accept_pair(_):\n",
    "        yi_tilde = psi_inverse_logistic(zi_tilde)\n",
    "        yj_tilde = psi_inverse_logistic(zj_tilde)\n",
    "        xi_tilde = yi_tilde + mu_star\n",
    "        xj_tilde = yj_tilde + mu_star\n",
    "        return xi_tilde, xj_tilde, True, z_accepted\n",
    "\n",
    "    return jax.lax.cond(in_supp_partner, accept_pair, reject_pair, operand=None)\n",
    "\n",
    "# -------------------------\n",
    "# Full x-update (same structure)\n",
    "# -------------------------\n",
    "@jit\n",
    "def delta_from_xi_xj_logistic(xi, xj, mu_star):\n",
    "    yi, yj = xi - mu_star, xj - mu_star\n",
    "    zi, zj = psi_logistic(yi), psi_logistic(yj)\n",
    "    return zi + zj\n",
    "\n",
    "delta_from_xi_xj_batch_logistic = vmap(delta_from_xi_xj_logistic, in_axes=(0, 0, None))\n",
    "\n",
    "@jit\n",
    "def update_x_full_jax_logistic(key, x_current, mu_current, mu_star, sigma_z):\n",
    "    m = x_current.shape[0]\n",
    "    assert m % 2 == 0\n",
    "\n",
    "    key_perm, key_pairs = random.split(key)\n",
    "    perm = random.permutation(key_perm, m)\n",
    "    x_perm = x_current[perm]\n",
    "\n",
    "    xis = x_perm[0::2]\n",
    "    xjs = x_perm[1::2]\n",
    "    n_pairs = xis.shape[0]\n",
    "    keys_pairs = random.split(key_pairs, n_pairs)\n",
    "\n",
    "    update_xi_xj_batch = vmap(\n",
    "        update_xi_xj_one_logistic,\n",
    "        in_axes=(0, 0, 0, None, None, None)\n",
    "    )\n",
    "\n",
    "    xis_new, xjs_new, pair_accepted_vec, z_accepted_vec = update_xi_xj_batch(\n",
    "        keys_pairs, xis, xjs, mu_current, mu_star, sigma_z\n",
    "    )\n",
    "\n",
    "    deltas = delta_from_xi_xj_batch_logistic(xis, xjs, mu_star)\n",
    "    deltas_new = delta_from_xi_xj_batch_logistic(xis_new, xjs_new, mu_star)\n",
    "\n",
    "    x_updated_pairs = jnp.stack([xis_new, xjs_new], axis=1).reshape(-1)\n",
    "    x_perm_new = x_perm.at[0:m].set(x_updated_pairs)\n",
    "    x_new = x_perm_new[jnp.argsort(perm)]\n",
    "\n",
    "    pair_accepted_count = jnp.sum(pair_accepted_vec)\n",
    "    z_accepted_count    = jnp.sum(z_accepted_vec)\n",
    "\n",
    "    return x_new, pair_accepted_count, z_accepted_count, deltas, deltas_new\n",
    "\n",
    "# -------------------------\n",
    "# Posterior for mu given x (logistic likelihood + normal prior)\n",
    "# -------------------------\n",
    "def unnormalized_posterior_mu_logpdf_logistic(mu: float, x: jnp.ndarray, prior_loc: float, prior_scale: float) -> float:\n",
    "    x = jnp.asarray(x)\n",
    "    mu = jnp.asarray(mu)\n",
    "\n",
    "    if mu.ndim == 0:\n",
    "        log_likelihood = jnp.sum(logistic_logpdf(x, loc=mu, scale=1.0))\n",
    "        log_prior = norm.logpdf(mu, loc=prior_loc, scale=prior_scale)\n",
    "    else:\n",
    "        log_likelihood = jnp.sum(logistic_logpdf(x[:, None], loc=mu[None, :], scale=1.0), axis=0)\n",
    "        log_prior = norm.logpdf(mu, loc=prior_loc, scale=prior_scale)\n",
    "\n",
    "    return log_likelihood + log_prior\n",
    "\n",
    "@jit\n",
    "def update_mu_metropolis_jax_logistic(key, mu_current, x_current, sigma_mu, prior_loc, prior_scale):\n",
    "    key_prop, key_u = random.split(key)\n",
    "    mu_candidate = mu_current + sigma_mu * random.normal(key_prop)\n",
    "\n",
    "    log_post_current = unnormalized_posterior_mu_logpdf_logistic(mu_current, x_current, prior_loc, prior_scale)\n",
    "    log_post_cand    = unnormalized_posterior_mu_logpdf_logistic(mu_candidate, x_current, prior_loc, prior_scale)\n",
    "\n",
    "    log_alpha = log_post_cand - log_post_current\n",
    "    log_alpha = jnp.where(jnp.isfinite(log_alpha), log_alpha, -jnp.inf)\n",
    "\n",
    "    u = random.uniform(key_u, minval=EPS_U, maxval=1.0)\n",
    "    accept = jnp.log(u) < log_alpha\n",
    "    mu_new = jnp.where(accept, mu_candidate, mu_current)\n",
    "    return mu_new, accept\n",
    "\n",
    "# -------------------------\n",
    "# Gibbs sampler (mu | x) then (x | mu, MLE=mu_star)\n",
    "# NOTE: x0 must satisfy sum psi(x0-mu_star)=0. Setting all x=mu_star works (psi(0)=0).\n",
    "# -------------------------\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_gibbs_sampler_mle_jax_logistic(key, mu_star: float, params: dict) -> dict:\n",
    "    T = params[\"num_iterations_T\"]\n",
    "    m = params[\"m\"]\n",
    "\n",
    "    mus = jnp.zeros(T + 1)\n",
    "    xs  = jnp.zeros((T + 1, m))\n",
    "\n",
    "    x0 = jnp.ones(m) * mu_star\n",
    "    xs  = xs.at[0, :].set(x0)\n",
    "    mus = mus.at[0].set(mu_star)\n",
    "\n",
    "    mu_acceptance_count = 0\n",
    "    z_i_acceptance_count = 0\n",
    "    pair_acceptance_count = 0\n",
    "    grad_likelihood_checks = jnp.zeros(T)\n",
    "\n",
    "    total_z_moves = T * (m // 2)\n",
    "\n",
    "    for t in tqdm(range(1, T + 1), desc=\"Running Gibbs Sampler (Logistic-loc)\"):\n",
    "        key, key_mu, key_x = random.split(key, 3)\n",
    "\n",
    "        # Step (a): mu | x\n",
    "        x_current = xs[t - 1]\n",
    "        mu_new, acc_mu = update_mu_metropolis_jax_logistic(\n",
    "            key_mu,\n",
    "            mus[t - 1],\n",
    "            x_current,\n",
    "            params[\"proposal_std_mu\"],\n",
    "            params[\"prior_mean\"],\n",
    "            params[\"prior_std\"],\n",
    "        )\n",
    "        mus = mus.at[t].set(mu_new)\n",
    "        mu_acceptance_count += acc_mu.astype(jnp.int32)\n",
    "\n",
    "        # Step (b): x | mu, MLE=mu_star\n",
    "        x_new, accepted_pairs, accepted_z_is, deltas, deltas_new = update_x_full_jax_logistic(\n",
    "            key_x, x_current, mus[t], mu_star, params[\"proposal_std_z\"]\n",
    "        )\n",
    "        xs = xs.at[t, :].set(x_new)\n",
    "\n",
    "        grad_likelihood_checks = grad_likelihood_checks.at[t - 1].set(\n",
    "            sum_psi_logistic(x_new - mu_star)\n",
    "        )\n",
    "        z_i_acceptance_count += accepted_z_is\n",
    "        pair_acceptance_count += accepted_pairs\n",
    "\n",
    "    mu_acceptance_rate   = mu_acceptance_count / T\n",
    "    z_i_acceptance_rate  = z_i_acceptance_count / total_z_moves\n",
    "    pair_acceptance_rate = pair_acceptance_count / total_z_moves\n",
    "\n",
    "    print(\"\\n--- Sampling Complete (Logistic-loc) ---\")\n",
    "    print(f\"Mu Acceptance Rate:  {float(mu_acceptance_rate):.4f}\")\n",
    "    print(f\"Z_i Acceptance Rate: {float(z_i_acceptance_rate):.4f}\")\n",
    "    print(f\"Pair Acceptance Rate:{float(pair_acceptance_rate):.4f}\")\n",
    "    print(f\"Score constraint check (last): {float(grad_likelihood_checks[-1]):.4e}\")\n",
    "\n",
    "    return {\n",
    "        \"mu_acceptance_rate\": mu_acceptance_rate,\n",
    "        \"pair_acceptance_rate\": pair_acceptance_rate,\n",
    "        \"z_i_acceptance_rate\": z_i_acceptance_rate,\n",
    "        \"mu_chain\": mus,\n",
    "        \"x_chain\": xs,\n",
    "        \"grad_likelihood_checks\": grad_likelihood_checks,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c337276e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# TEST + RUN SCRIPT (Location-Logistic, scale=1 known)\n",
    "# Assumes you already pasted/defined the logistic functions from my previous message:\n",
    "#   - run_gibbs_sampler_mle_jax_logistic\n",
    "#   - (and all helpers it calls)\n",
    "# =========================\n",
    "\n",
    "import jax\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# -------------------------\n",
    "# Helper: simple summaries\n",
    "# -------------------------\n",
    "def summarize_chain(name, chain, burn=0, thin=1):\n",
    "    chain = jnp.asarray(chain)\n",
    "    chain = chain[burn::thin]\n",
    "    return {\n",
    "        \"name\": name,\n",
    "        \"n\": int(chain.shape[0]),\n",
    "        \"mean\": float(jnp.mean(chain)),\n",
    "        \"std\": float(jnp.std(chain)),\n",
    "        \"q05\": float(jnp.quantile(chain, 0.05)),\n",
    "        \"q50\": float(jnp.quantile(chain, 0.50)),\n",
    "        \"q95\": float(jnp.quantile(chain, 0.95)),\n",
    "    }\n",
    "\n",
    "def quick_plot_mu(mu_chain, burn=0, thin=1, title=\"mu chain\"):\n",
    "    mu = jnp.asarray(mu_chain)[burn::thin]\n",
    "    plt.figure()\n",
    "    plt.plot(mu)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"iteration (post burn/thin)\")\n",
    "    plt.ylabel(\"mu\")\n",
    "    plt.show()\n",
    "\n",
    "def quick_plot_constraint(checks, title=\"score constraint check\"):\n",
    "    c = jnp.asarray(checks)\n",
    "    plt.figure()\n",
    "    plt.plot(c)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"iteration\")\n",
    "    plt.ylabel(\"sum_i tanh((x_i-mu*)/2)\")\n",
    "    plt.show()\n",
    "\n",
    "def quick_hist_mu(mu_chain, burn=0, thin=1, title=\"mu posterior (approx)\"):\n",
    "    mu = jnp.asarray(mu_chain)[burn::thin]\n",
    "    plt.figure()\n",
    "    plt.hist(mu, bins=40, density=True)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"mu\")\n",
    "    plt.ylabel(\"density\")\n",
    "    plt.show()\n",
    "\n",
    "# -------------------------\n",
    "# Main test runner\n",
    "# -------------------------\n",
    "def main():\n",
    "    # ----- RNG\n",
    "    seed = 0\n",
    "    key = random.PRNGKey(seed)\n",
    "\n",
    "    # ----- MLE constraint value\n",
    "    mu_star = 0.0\n",
    "\n",
    "    # ----- Sampler params\n",
    "    # Tune proposal_std_z first: acceptance ~ 0.2-0.6 is often OK.\n",
    "    params = {\n",
    "        \"num_iterations_T\": 100000,   # increase to 2e4+ for real runs\n",
    "        \"m\": 6,                   # must be even (pairs)\n",
    "        \"proposal_std_z\": .001,     # z RW scale inside truncated normal\n",
    "        \"proposal_std_mu\": 0.50,    # mu RW scale\n",
    "        \"prior_mean\": 0.0,\n",
    "        \"prior_std\": 5.0,\n",
    "    }\n",
    "\n",
    "    # ----- Run Gibbs\n",
    "    results = run_gibbs_sampler_mle_jax_logistic(key, mu_star=mu_star, params=params)\n",
    "\n",
    "    # ----- Basic diagnostics\n",
    "    T = params[\"num_iterations_T\"]\n",
    "    burn = int(0.3 * T)\n",
    "    thin = 1\n",
    "\n",
    "    print(\"\\n--- Diagnostics ---\")\n",
    "    print(\"Acceptance rates:\")\n",
    "    print(f\"  mu:   {float(results['mu_acceptance_rate']):.3f}\")\n",
    "    print(f\"  z_i:  {float(results['z_i_acceptance_rate']):.3f}\")\n",
    "    print(f\"  pair: {float(results['pair_acceptance_rate']):.3f}\")\n",
    "\n",
    "    summ = summarize_chain(\"mu\", results[\"mu_chain\"], burn=burn, thin=thin)\n",
    "    print(\"\\nmu posterior summary (after burn):\")\n",
    "    for k, v in summ.items():\n",
    "        if k != \"name\":\n",
    "            print(f\"  {k}: {v}\")\n",
    "\n",
    "    # Constraint check: should hover near 0\n",
    "    checks = results[\"grad_likelihood_checks\"]\n",
    "    print(\"\\nConstraint check:\")\n",
    "    print(f\"  mean(abs(check)) after burn: {float(jnp.mean(jnp.abs(checks[burn:]))):.3e}\")\n",
    "    print(f\"  max(abs(check))  after burn: {float(jnp.max(jnp.abs(checks[burn:]))):.3e}\")\n",
    "\n",
    "    # ----- Plots\n",
    "    quick_plot_mu(results[\"mu_chain\"], burn=burn, thin=thin, title=\"mu chain (Logistic-loc | MLE constraint)\")\n",
    "    quick_hist_mu(results[\"mu_chain\"], burn=burn, thin=thin, title=\"mu posterior (approx) after burn\")\n",
    "    quick_plot_constraint(results[\"grad_likelihood_checks\"], title=\"Constraint check over iterations\")\n",
    "\n",
    "    # Optional: check that x stays on manifold (spot-check last x)\n",
    "    x_last = results[\"x_chain\"][-1]\n",
    "    constraint_last = sum_psi_logistic(x_last - mu_star)\n",
    "    print(f\"\\nConstraint at last x: {float(constraint_last):.3e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
